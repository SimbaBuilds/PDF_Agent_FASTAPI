"""
Semantic Search Service

A service for performing semantic similarity searches using database optimization.
Uses OpenAI embeddings via API for query generation and Supabase database functions for efficient search.
Designed to be extensible for use across multiple agents.
"""

import logging
import asyncio
import time
from typing import List, Dict, Any, Optional, Tuple
from supabase import Client as SupabaseClient
from datetime import datetime
from uuid import UUID, uuid4
from app.utils.logging.component_loggers import (
    get_search_logger, 
    log_performance_event,
    log_function_calls
)
from app.utils.circuit_breaker import get_circuit_breaker, CircuitBreakerOpenException

logger = get_search_logger(__name__)
circuit_breaker = get_circuit_breaker()


class SemanticSearchService:
    """
    Service for generating embeddings and performing semantic similarity searches.
    
    This service provides:
    - Embedding generation using sentence-transformers
    - Similarity search with relevance score boosting
    - Extensible interface for multiple agents
    """
    
    def __init__(self):
        """
        Initialize the semantic search service.
        Uses OpenAI API for embedding generation.
        """
        self.embedding_dimension = 1536  # Dimension for OpenAI text-embedding-3-small
        logger.info("Initialized semantic search service using OpenAI embeddings", extra={
            'embedding_dimension': self.embedding_dimension,
            'action': 'service_initialization_complete'
        })
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        DEPRECATED: Embedding generation is now handled by Supabase Edge Functions.
        This method is kept for backward compatibility but will raise an error.
        Use queue_embedding_job() instead.
        
        Args:
            text: Input text to embed
            
        Returns:
            List of floats representing the embedding vector
        """
        logger.warning("generate_embedding() is deprecated. Use Supabase Edge Functions for embedding generation.")
        raise RuntimeError("Embedding generation moved to Supabase Edge Functions. Use queue_embedding_job() instead.")
    
    def _generate_query_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for query text using OpenAI API (for search purposes).
        This ensures compatibility with resource embeddings generated by Edge Functions.
        
        Args:
            text: Query text to embed
            
        Returns:
            List of floats representing the embedding vector
        """
        import os
        import requests
        
        start_time = time.time()
        text_length = len(text)
        
        logger.debug(f"Generating query embedding for text of length {text_length}", extra={
            'text_length': text_length,
            'action': 'query_embedding_generation_start'
        })
        
        try:
            # Use OpenAI API for consistency with Edge Function
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if not openai_api_key:
                raise RuntimeError("OPENAI_API_KEY environment variable not set")
            
            response = requests.post(
                "https://api.openai.com/v1/embeddings",
                headers={
                    "Authorization": f"Bearer {openai_api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "input": text,
                    "model": "text-embedding-3-small",  # Same model as Edge Function
                },
                timeout=2  # 1 second timeout for API calls
            )
            
            if not response.ok:
                raise RuntimeError(f"OpenAI API request failed: {response.status_code} {response.text}")
            
            data = response.json()
            embedding = data["data"][0]["embedding"]
            
            duration = time.time() - start_time
            log_performance_event(
                logger,
                f"Generated query embedding for text of length {text_length}",
                duration,
                text_length=text_length,
                embedding_size=len(embedding),
                action='query_embedding_generation_complete'
            )
            
            return embedding
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Failed to generate query embedding: {str(e)}", extra={
                'text_length': text_length,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'query_embedding_generation_error'
            })
            raise RuntimeError(f"Failed to generate query embedding: {str(e)}")
    
    def batch_generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        DEPRECATED: Batch embedding generation is now handled by Supabase Edge Functions.
        This method is kept for backward compatibility but will raise an error.
        
        Args:
            texts: List of input texts to embed
            
        Returns:
            List of embedding vectors
        """
        logger.warning("batch_generate_embeddings() is deprecated. Use Supabase Edge Functions for embedding generation.")
        raise RuntimeError("Batch embedding generation moved to Supabase Edge Functions.")
    
    
    def search_resources_by_embedding_db(
        self,
        query_embedding: List[float],
        user_id: str,
        supabase: SupabaseClient,
        similarity_threshold: float = 0.3,
        max_results: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Perform semantic search using the PostgreSQL function for optimal performance.
        
        Args:
            query_embedding: Pre-generated embedding vector
            user_id: User ID to filter resources
            supabase: Supabase client for database operations
            similarity_threshold: Minimum similarity score to include results
            max_results: Maximum number of results to return
            
        Returns:
            List of matching resources with similarity scores
        """
        start_time = time.time()
        
        logger.info(f"Starting database-optimized semantic search for user {user_id}", extra={
            'user_id': user_id,
            'similarity_threshold': similarity_threshold,
            'max_results': max_results,
            'method': 'database_function',
            'action': 'semantic_search_db_start'
        })
        
        try:
            # Call the PostgreSQL function for optimized vector search with circuit breaker
            def search_query():
                return supabase.rpc('search_resources_by_embedding', {
                    'query_embedding': query_embedding,
                    'user_id_param': user_id,
                    'similarity_threshold': similarity_threshold,
                    'max_results': max_results
                }).execute()
            
            db_start = time.time()
            result = circuit_breaker.protect_query(search_query)
            db_duration = time.time() - db_start
            
            if not result.data:
                logger.info("No resources found by database function", extra={
                    'user_id': user_id,
                    'db_duration_seconds': db_duration,
                    'action': 'semantic_search_db_no_results'
                })
                return []
            
            # Format results to match the expected structure
            formatted_results = []
            for row in result.data:
                formatted_results.append({
                    'resource': {
                        'id': row['id'],
                        'title': row['title'],
                        'content': row['content'],
                        'type': row['type'],
                        'relevance_score': row['relevance_score'],
                        'instructions': row['instructions'],
                        'tag_1_id': row['tag_1_id'],
                        'tag_2_id': row['tag_2_id'],
                        'tag_3_id': row['tag_3_id'],
                        'tag_4_id': row['tag_4_id'],
                        'tag_5_id': row['tag_5_id'],
                        'last_accessed': row['last_accessed'],
                        'created_at': row['created_at'],
                        'updated_at': row['updated_at']
                    },
                    'similarity_score': row['similarity_score'],
                    'final_score': row['final_score'],
                    'relevance_boost': row['final_score'] - row['similarity_score']
                })
            
            total_duration = time.time() - start_time
            
            logger.info(f"Database semantic search completed successfully", extra={
                'user_id': user_id,
                'results_returned': len(formatted_results),
                'duration_seconds': total_duration,
                'db_duration_seconds': db_duration,
                'method': 'database_function',
                'action': 'semantic_search_db_complete'
            })
            
            return formatted_results
            
        except CircuitBreakerOpenException as e:
            duration = time.time() - start_time
            logger.warning(f"Search circuit breaker is open: {str(e)}", extra={
                'user_id': user_id,
                'duration_seconds': duration,
                'method': 'database_function',
                'action': 'semantic_search_circuit_open'
            })
            return []
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Database semantic search failed: {str(e)}", extra={
                'user_id': user_id,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'method': 'database_function',
                'action': 'semantic_search_db_error'
            })
            # Don't raise the exception, let it fall back to fallback method
            return []
    
    def search_resources_by_embedding_with_type_db(
        self,
        query_embedding: List[float],
        user_id: str,
        supabase: SupabaseClient,
        resource_type: str,
        similarity_threshold: float = 0.3,
        max_results: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Perform type-filtered semantic search using the PostgreSQL function.
        
        Args:
            query_embedding: Pre-generated embedding vector
            user_id: User ID to filter resources
            supabase: Supabase client for database operations
            resource_type: Type of resource to filter
            similarity_threshold: Minimum similarity score to include results
            max_results: Maximum number of results to return
            
        Returns:
            List of matching resources with similarity scores
        """
        start_time = time.time()
        
        logger.info(f"Starting type-filtered database semantic search for user {user_id}", extra={
            'user_id': user_id,
            'resource_type': resource_type,
            'similarity_threshold': similarity_threshold,
            'max_results': max_results,
            'method': 'database_type_filtered',
            'action': 'semantic_search_type_db_start'
        })
        
        try:
            # Call the type-filtered PostgreSQL function with circuit breaker
            def type_search_query():
                # Add timeout to the RPC call to prevent hanging
                return supabase.rpc('search_resources_by_embedding_with_type', {
                    'query_embedding': query_embedding,
                    'user_id_param': user_id,
                    'resource_type_param': resource_type,
                    'similarity_threshold': similarity_threshold,
                    'max_results': max_results
                }).execute()
            
            db_start = time.time()
            result = circuit_breaker.protect_query(type_search_query)
            db_duration = time.time() - db_start
            
            if not result.data:
                logger.info("No resources found by type-filtered database function", extra={
                    'user_id': user_id,
                    'resource_type': resource_type,
                    'db_duration_seconds': db_duration,
                    'action': 'semantic_search_type_db_no_results'
                })
                return []
            
            # Format results to match the expected structure
            formatted_results = []
            for row in result.data:
                formatted_results.append({
                    'resource': {
                        'id': row['id'],
                        'title': row['title'],
                        'content': row['content'],
                        'type': row['type'],
                        'relevance_score': row['relevance_score'],
                        'instructions': row['instructions'],
                        'tag_1_id': row['tag_1_id'],
                        'tag_2_id': row['tag_2_id'],
                        'tag_3_id': row['tag_3_id'],
                        'tag_4_id': row['tag_4_id'],
                        'tag_5_id': row['tag_5_id'],
                        'last_accessed': row['last_accessed'],
                        'created_at': row['created_at'],
                        'updated_at': row['updated_at']
                    },
                    'similarity_score': row['similarity_score'],
                    'final_score': row['final_score'],
                    'relevance_boost': row['final_score'] - row['similarity_score']
                })
            
            total_duration = time.time() - start_time
            
            logger.info(f"Type-filtered database semantic search completed successfully", extra={
                'user_id': user_id,
                'resource_type': resource_type,
                'results_returned': len(formatted_results),
                'duration_seconds': total_duration,
                'db_duration_seconds': db_duration,
                'method': 'database_type_filtered',
                'action': 'semantic_search_type_db_complete'
            })
            
            return formatted_results
            
        except CircuitBreakerOpenException as e:
            duration = time.time() - start_time
            logger.warning(f"Type search circuit breaker is open: {str(e)}", extra={
                'user_id': user_id,
                'resource_type': resource_type,
                'duration_seconds': duration,
                'method': 'database_type_filtered',
                'action': 'semantic_search_type_circuit_open'
            })
            return []
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Type-filtered database semantic search failed: {str(e)}", extra={
                'user_id': user_id,
                'resource_type': resource_type,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'method': 'database_type_filtered',
                'action': 'semantic_search_type_db_error'
            })
            return []
    
    def search_resources(
        self,
        query: str,
        user_id: str,
        supabase: SupabaseClient,
        similarity_threshold: float = 0.3,
        max_results: int = 10,
        use_relevance_boost: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Perform semantic search on user resources with automatic optimization.
        
        Args:
            query: Search query text
            user_id: User ID to filter resources
            supabase: Supabase client for database operations
            similarity_threshold: Minimum similarity score to include results
            max_results: Maximum number of results to return
            use_relevance_boost: Whether to boost results based on relevance_score
            
        Returns:
            List of matching resources with similarity scores
        """
        start_time = time.time()
        
        logger.info(f"Starting semantic search for user {user_id}", extra={
            'user_id': user_id,
            'query_length': len(query),
            'similarity_threshold': similarity_threshold,
            'max_results': max_results,
            'use_relevance_boost': use_relevance_boost,
            'action': 'semantic_search_start'
        })
        
        try:
            # Generate query embedding using fallback model for search queries only
            query_embedding = self._generate_query_embedding(query)
            
            # Use database function for optimal performance
            results = self.search_resources_by_embedding_db(
                query_embedding=query_embedding,
                user_id=user_id,
                supabase=supabase,
                similarity_threshold=similarity_threshold,
                max_results=max_results
            )
            
            total_duration = time.time() - start_time
            logger.info(f"Semantic search completed", extra={
                'user_id': user_id,
                'results_returned': len(results),
                'duration_seconds': total_duration,
                'method': 'database_optimized',
                'action': 'semantic_search_complete'
            })
            
            return results
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Failed to search resources: {str(e)}", extra={
                'user_id': user_id,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'semantic_search_error'
            })
            return []
    
    def search_resources_by_type(
        self,
        query: str,
        user_id: str,
        supabase: SupabaseClient,
        resource_type: str,
        similarity_threshold: float = 0.3,
        max_results: int = 10,
        use_relevance_boost: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Perform semantic search on user resources filtered by type.

        Args:
            query: Search query text
            user_id: User ID to filter resources
            supabase: Supabase client for database operations
            resource_type: Type of resource to filter (e.g., "memory", "document", "file")
            similarity_threshold: Minimum similarity score to include results
            max_results: Maximum number of results to return
            use_relevance_boost: Whether to boost results based on relevance_score

        Returns:
            List of matching resources with similarity scores
        """
        start_time = time.time()

        logger.info(f"Starting type-filtered semantic search for user {user_id}", extra={
            'user_id': user_id,
            'resource_type': resource_type,
            'query_length': len(query),
            'similarity_threshold': similarity_threshold,
            'max_results': max_results,
            'use_relevance_boost': use_relevance_boost,
            'action': 'semantic_search_by_type_start'
        })

        try:
            # Generate query embedding using fallback model for search queries only
            query_embedding = self._generate_query_embedding(query)

            # Use type-filtered database function for optimal performance
            results = self.search_resources_by_embedding_with_type_db(
                query_embedding=query_embedding,
                user_id=user_id,
                supabase=supabase,
                resource_type=resource_type,
                similarity_threshold=similarity_threshold,
                max_results=max_results
            )

            total_duration = time.time() - start_time
            logger.info(f"Type-filtered semantic search completed", extra={
                'user_id': user_id,
                'resource_type': resource_type,
                'results_returned': len(results),
                'duration_seconds': total_duration,
                'method': 'database_type_filtered',
                'action': 'semantic_search_by_type_complete'
            })

            return results

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Failed to search resources by type: {str(e)}", extra={
                'user_id': user_id,
                'resource_type': resource_type,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'semantic_search_by_type_error'
            })
            return []

    def search_resources_by_embedding_with_tag_db(
        self,
        query_embedding: List[float],
        user_id: str,
        supabase: SupabaseClient,
        tag_name: str,
        similarity_threshold: float = 0.3,
        max_results: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Perform tag-filtered semantic search using the PostgreSQL function.

        Args:
            query_embedding: Pre-generated embedding vector
            user_id: User ID to filter resources
            supabase: Supabase client for database operations
            tag_name: Name of tag to filter by
            similarity_threshold: Minimum similarity score to include results
            max_results: Maximum number of results to return

        Returns:
            List of matching resources with similarity scores
        """
        start_time = time.time()

        logger.info(f"Starting tag-filtered database semantic search for user {user_id}", extra={
            'user_id': user_id,
            'tag_name': tag_name,
            'similarity_threshold': similarity_threshold,
            'max_results': max_results,
            'method': 'database_tag_filtered',
            'action': 'semantic_search_tag_db_start'
        })

        try:
            # Call the tag-filtered PostgreSQL function with circuit breaker
            def tag_search_query():
                return supabase.rpc('search_resources_by_tag', {
                    'query_embedding': query_embedding,
                    'user_id_param': user_id,
                    'tag_name_param': tag_name,
                    'similarity_threshold': similarity_threshold,
                    'max_results': max_results
                }).execute()

            db_start = time.time()
            result = circuit_breaker.protect_query(tag_search_query)
            db_duration = time.time() - db_start

            if not result.data:
                logger.info("No resources found by tag-filtered database function", extra={
                    'user_id': user_id,
                    'tag_name': tag_name,
                    'db_duration_seconds': db_duration,
                    'action': 'semantic_search_tag_db_no_results'
                })
                return []

            # Format results to match the expected structure
            formatted_results = []
            for row in result.data:
                formatted_results.append({
                    'resource': {
                        'id': row['id'],
                        'title': row['title'],
                        'content': row['content'],
                        'type': row['type'],
                        'relevance_score': row['relevance_score'],
                        'instructions': row['instructions'],
                        'tag_1_id': row['tag_1_id'],
                        'tag_2_id': row['tag_2_id'],
                        'tag_3_id': row['tag_3_id'],
                        'tag_4_id': row['tag_4_id'],
                        'tag_5_id': row['tag_5_id'],
                        'last_accessed': row['last_accessed'],
                        'created_at': row['created_at'],
                        'updated_at': row['updated_at']
                    },
                    'similarity_score': row['similarity_score'],
                    'final_score': row['final_score'],
                    'relevance_boost': row['final_score'] - row['similarity_score']
                })

            total_duration = time.time() - start_time

            logger.info(f"Tag-filtered database semantic search completed successfully", extra={
                'user_id': user_id,
                'tag_name': tag_name,
                'results_returned': len(formatted_results),
                'duration_seconds': total_duration,
                'db_duration_seconds': db_duration,
                'method': 'database_tag_filtered',
                'action': 'semantic_search_tag_db_complete'
            })

            return formatted_results

        except CircuitBreakerOpenException as e:
            duration = time.time() - start_time
            logger.warning(f"Tag search circuit breaker is open: {str(e)}", extra={
                'user_id': user_id,
                'tag_name': tag_name,
                'duration_seconds': duration,
                'method': 'database_tag_filtered',
                'action': 'semantic_search_tag_circuit_open'
            })
            return []
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Tag-filtered database semantic search failed: {str(e)}", extra={
                'user_id': user_id,
                'tag_name': tag_name,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'method': 'database_tag_filtered',
                'action': 'semantic_search_tag_db_error'
            })
            return []

    def search_resources_by_tag(
        self,
        query: str,
        user_id: str,
        supabase: SupabaseClient,
        tag_name: str,
        similarity_threshold: float = 0.3,
        max_results: int = 10,
        use_relevance_boost: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Perform semantic search on user resources filtered by tag name.

        Args:
            query: Search query text
            user_id: User ID to filter resources
            supabase: Supabase client for database operations
            tag_name: Name of tag to filter by (e.g., "Health and Wellness")
            similarity_threshold: Minimum similarity score to include results
            max_results: Maximum number of results to return
            use_relevance_boost: Whether to boost results based on relevance_score

        Returns:
            List of matching resources with similarity scores
        """
        start_time = time.time()

        logger.info(f"Starting tag-filtered semantic search for user {user_id}", extra={
            'user_id': user_id,
            'tag_name': tag_name,
            'query_length': len(query),
            'similarity_threshold': similarity_threshold,
            'max_results': max_results,
            'use_relevance_boost': use_relevance_boost,
            'action': 'semantic_search_by_tag_start'
        })

        try:
            # Generate query embedding using fallback model for search queries only
            query_embedding = self._generate_query_embedding(query)

            # Use tag-filtered database function for optimal performance
            results = self.search_resources_by_embedding_with_tag_db(
                query_embedding=query_embedding,
                user_id=user_id,
                supabase=supabase,
                tag_name=tag_name,
                similarity_threshold=similarity_threshold,
                max_results=max_results
            )

            total_duration = time.time() - start_time
            logger.info(f"Tag-filtered semantic search completed", extra={
                'user_id': user_id,
                'tag_name': tag_name,
                'results_returned': len(results),
                'duration_seconds': total_duration,
                'method': 'database_tag_filtered',
                'action': 'semantic_search_by_tag_complete'
            })

            return results

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Failed to search resources by tag: {str(e)}", extra={
                'user_id': user_id,
                'tag_name': tag_name,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'semantic_search_by_tag_error'
            })
            return []
    
    def queue_embedding_job(
        self,
        resource_id: str,
        content: str,
        user_id: str,
        supabase: SupabaseClient
    ) -> bool:
        """
        Queue an embedding job for async processing via Supabase Edge Functions.

        Args:
            resource_id: ID of the resource to embed
            content: Content to embed
            user_id: User ID for validation
            supabase: Supabase client for database operations

        Returns:
            True if job was queued successfully, False otherwise
        """
        start_time = time.time()

        logger.info(f"Queuing embedding job for resource {resource_id}", extra={
            'resource_id': resource_id,
            'user_id': user_id,
            'content_length': len(content),
            'action': 'queue_embedding_job_start'
        })

        try:
            # Call the database function to queue the embedding job
            result = supabase.rpc('queue_embedding_job', {
                'p_resource_id': resource_id,
                'p_user_id': user_id,
                'p_content': content
            }).execute()

            if result.data:
                job_id = result.data
                duration = time.time() - start_time
                logger.info(f"Successfully queued embedding job {job_id} for resource {resource_id}", extra={
                    'resource_id': resource_id,
                    'user_id': user_id,
                    'job_id': job_id,
                    'duration_seconds': duration,
                    'action': 'queue_embedding_job_complete'
                })
                return True
            else:
                logger.warning(f"Failed to queue embedding job for resource {resource_id}", extra={
                    'resource_id': resource_id,
                    'user_id': user_id,
                    'action': 'queue_embedding_job_failed'
                })
                return False

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Failed to queue embedding job: {str(e)}", extra={
                'resource_id': resource_id,
                'user_id': user_id,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'queue_embedding_job_error'
            })
            return False

    def queue_embedding_job_for_record_page(
        self,
        record_page_id: str,
        content: str,
        user_id: str,
        supabase: SupabaseClient
    ) -> bool:
        """
        Queue an embedding job for a record page for async processing via Supabase Edge Functions.

        Args:
            record_page_id: ID of the record page to embed
            content: Content to embed
            user_id: User ID for validation
            supabase: Supabase client for database operations

        Returns:
            True if job was queued successfully, False otherwise
        """
        start_time = time.time()

        logger.info(f"Queuing embedding job for record page {record_page_id}", extra={
            'record_page_id': record_page_id,
            'user_id': user_id,
            'content_length': len(content),
            'action': 'queue_embedding_job_record_page_start'
        })

        try:
            # Insert directly into embedding_jobs table for record pages
            job_data = {
                'id': str(uuid4()),  # Generate UUID
                'table_name': 'record_pages',
                'record_page_id': record_page_id,
                'resource_id': None,  # NULL for record pages
                'user_id': user_id,
                'content': content,
                'status': 'pending',
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }

            result = supabase.from_('embedding_jobs').insert(job_data).execute()

            if result.data:
                job_id = result.data[0]['id']
                duration = time.time() - start_time
                logger.info(f"Successfully queued embedding job {job_id} for record page {record_page_id}", extra={
                    'record_page_id': record_page_id,
                    'user_id': user_id,
                    'job_id': job_id,
                    'duration_seconds': duration,
                    'action': 'queue_embedding_job_record_page_complete'
                })
                return True
            else:
                logger.warning(f"Failed to queue embedding job for record page {record_page_id}", extra={
                    'record_page_id': record_page_id,
                    'user_id': user_id,
                    'action': 'queue_embedding_job_record_page_failed'
                })
                return False

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Failed to queue embedding job for record page: {str(e)}", extra={
                'record_page_id': record_page_id,
                'user_id': user_id,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'queue_embedding_job_record_page_error'
            })
            return False

    async def batch_queue_embedding_jobs_for_record_pages(
        self,
        page_jobs: List[Dict[str, str]],
        user_id: str,
        supabase: SupabaseClient
    ) -> bool:
        """
        Batch queue embedding jobs for multiple record pages in a single database operation.

        Args:
            page_jobs: List of dicts with 'record_page_id' and 'content' keys
            user_id: User ID for validation
            supabase: Supabase client for database operations

        Returns:
            True if all jobs were queued successfully, False otherwise
        """
        if not page_jobs:
            return True

        start_time = time.time()
        job_count = len(page_jobs)

        logger.info(f"Batch queuing {job_count} embedding jobs for record pages", extra={
            'user_id': user_id,
            'job_count': job_count,
            'action': 'batch_queue_embedding_jobs_start'
        })

        try:
            # Prepare all job data at once
            now = datetime.now().isoformat()
            batch_job_data = []

            for page_job in page_jobs:
                job_data = {
                    'id': str(uuid4()),
                    'table_name': 'record_pages',
                    'record_page_id': page_job['record_page_id'],
                    'resource_id': None,  # NULL for record pages
                    'user_id': user_id,
                    'content': page_job['content'],
                    'status': 'pending',
                    'created_at': now,
                    'updated_at': now
                }
                batch_job_data.append(job_data)

            # Single batch insert operation (run in thread pool to avoid blocking)
            result = await asyncio.to_thread(
                lambda: supabase.from_('embedding_jobs').insert(batch_job_data).execute()
            )

            if result.data and len(result.data) == job_count:
                duration = time.time() - start_time
                logger.info(f"Successfully batch queued {job_count} embedding jobs", extra={
                    'user_id': user_id,
                    'job_count': job_count,
                    'duration_seconds': duration,
                    'action': 'batch_queue_embedding_jobs_complete'
                })
                return True
            else:
                logger.warning(f"Failed to batch queue embedding jobs. Expected {job_count}, got {len(result.data) if result.data else 0}", extra={
                    'user_id': user_id,
                    'expected_count': job_count,
                    'actual_count': len(result.data) if result.data else 0,
                    'action': 'batch_queue_embedding_jobs_partial_failure'
                })
                return False

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Failed to batch queue embedding jobs: {str(e)}", extra={
                'user_id': user_id,
                'job_count': job_count,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'batch_queue_embedding_jobs_error'
            })
            return False
    
    def update_resource_embedding(
        self,
        resource_id: str,
        content: str,
        user_id: str,
        supabase: SupabaseClient
    ) -> bool:
        """
        DEPRECATED: Direct embedding updates are now handled by Supabase Edge Functions.
        Use queue_embedding_job() instead.
        
        Args:
            resource_id: ID of the resource to update
            content: New content to embed
            user_id: User ID for validation
            supabase: Supabase client for database operations
            
        Returns:
            True if successful, False otherwise
        """
        logger.warning("update_resource_embedding() is deprecated. Using queue_embedding_job() instead.")
        return self.queue_embedding_job(resource_id, content, user_id, supabase)
    
    def boost_resource_relevance(
        self,
        resource_id: str,
        user_id: str,
        supabase: SupabaseClient,
        new_relevance_score: int = 100,
        new_decay_factor: float = 0.8
    ) -> bool:
        """
        Boost a resource's relevance score and reset its decay factor.
        Called when a resource is successfully retrieved via search.
        
        Args:
            resource_id: ID of the resource to boost
            user_id: User ID for validation
            supabase: Supabase client for database operations
            new_relevance_score: New relevance score (default 100)
            new_decay_factor: New decay factor (default 0.8)
            
        Returns:
            True if successful, False otherwise
        """
        logger.info(f"Boosting relevance for resource {resource_id}", extra={
            'resource_id': resource_id,
            'user_id': user_id,
            'new_relevance_score': new_relevance_score,
            'new_decay_factor': new_decay_factor,
            'action': 'boost_resource_relevance_start'
        })
        
        try:
            # Update resource relevance and decay factor
            result = supabase.from_('resources').update({
                'relevance_score': new_relevance_score,
                'decay_factor': new_decay_factor,
                'last_accessed': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }).eq('id', resource_id).eq('user_id', user_id).execute()
            
            if result.data:
                logger.info(f"Successfully boosted relevance for resource {resource_id}", extra={
                    'resource_id': resource_id,
                    'user_id': user_id,
                    'new_relevance_score': new_relevance_score,
                    'new_decay_factor': new_decay_factor,
                    'action': 'boost_resource_relevance_complete'
                })
                return True
            else:
                logger.warning(f"Failed to boost relevance for resource {resource_id}", extra={
                    'resource_id': resource_id,
                    'user_id': user_id,
                    'action': 'boost_resource_relevance_failed'
                })
                return False
                
        except Exception as e:
            logger.error(f"Failed to boost resource relevance: {str(e)}", extra={
                'resource_id': resource_id,
                'user_id': user_id,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'action': 'boost_resource_relevance_error'
            })
            return False
    
    def search_by_tags_and_keywords(
        self,
        keywords: List[str],
        tags: List[str],
        user_id: str,
        supabase: SupabaseClient,
        max_results: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Search resources by keywords and tags (fallback for semantic search).
        
        Args:
            keywords: List of keywords to search for in content
            tags: List of tag names to filter by
            user_id: User ID to filter resources
            supabase: Supabase client for database operations
            max_results: Maximum number of results to return
            
        Returns:
            List of matching resources
        """
        try:
            # Start with user's resources
            query = supabase.from_('resources').select(
                'id, title, content, type, relevance_score, instructions, '
                'tag_1_id, tag_2_id, tag_3_id, tag_4_id, tag_5_id, '
                'last_accessed, created_at, updated_at'
            ).eq('user_id', user_id)
            
            # Apply keyword filter if provided
            if keywords:
                # Use OR condition for keywords in content or title
                # Build filter conditions for each keyword
                for keyword in keywords:
                    query = query.or_(f'content.ilike.%{keyword}%,title.ilike.%{keyword}%')
            
            # Execute query
            resources_result = query.execute()
            
            if not resources_result.data:
                return []
            
            results = []
            
            # Filter by tags if provided
            if tags:
                # Get tag IDs for filtering
                tag_ids = []
                for tag_name in tags:
                    tag_result = supabase.from_('tags').select('id').eq('name', tag_name).execute()
                    if tag_result.data:
                        tag_ids.append(tag_result.data[0]['id'])
                
                # Filter resources by tag IDs
                for resource in resources_result.data:
                    resource_tag_ids = [
                        resource.get('tag_1_id'),
                        resource.get('tag_2_id'),
                        resource.get('tag_3_id'),
                        resource.get('tag_4_id'),
                        resource.get('tag_5_id')
                    ]
                    
                    # Check if any resource tag matches our search tags
                    if any(tag_id in tag_ids for tag_id in resource_tag_ids if tag_id):
                        results.append({
                            'resource': resource,
                            'similarity_score': 0.0,  # No similarity score for keyword search
                            'final_score': resource.get('relevance_score', 0) / 100  # Use relevance as score
                        })
            else:
                # No tag filtering, return all keyword matches
                for resource in resources_result.data:
                    results.append({
                        'resource': resource,
                        'similarity_score': 0.0,
                        'final_score': resource.get('relevance_score', 0) / 100
                    })
            
            # Sort by relevance score (highest first)
            results.sort(key=lambda x: x['final_score'], reverse=True)
            
            # Return top results
            return results[:max_results]
            
        except Exception as e:
            logger.error(f"Failed to search by tags and keywords: {str(e)}")
            return []


    def search_pdf_pages_by_embedding(
        self,
        query: str,
        user_id: str,
        supabase: SupabaseClient,
        pdf_id: Optional[str] = None,
        similarity_threshold: float = 0.3,
        max_results: int = 5
    ) -> List[Dict[str, Any]]:
        """
        Search PDF pages by semantic similarity.

        Args:
            query: Search query text
            user_id: User ID to filter pages
            supabase: Supabase client for database operations
            pdf_id: Optional PDF ID to limit search to specific document
            similarity_threshold: Minimum similarity score to include results
            max_results: Maximum number of results to return

        Returns:
            List of matching pages with similarity scores
        """
        start_time = time.time()

        logger.info(f"Starting PDF page semantic search for user {user_id}", extra={
            'user_id': user_id,
            'pdf_id': pdf_id,
            'query_length': len(query),
            'similarity_threshold': similarity_threshold,
            'max_results': max_results,
            'action': 'search_pdf_pages_start'
        })

        try:
            # Generate query embedding
            query_embedding = self._generate_query_embedding(query)

            # Call the RPC function for vector similarity search
            def search_query():
                return supabase.rpc('search_pdf_pages_by_embedding', {
                    'query_embedding': query_embedding,
                    'target_user_id': user_id,
                    'target_pdf_id': pdf_id,
                    'match_threshold': similarity_threshold,
                    'match_count': max_results
                }).execute()

            db_start = time.time()
            result = circuit_breaker.protect_query(search_query)
            db_duration = time.time() - db_start

            if not result.data:
                logger.info("No PDF pages found by semantic search", extra={
                    'user_id': user_id,
                    'pdf_id': pdf_id,
                    'db_duration_seconds': db_duration,
                    'action': 'search_pdf_pages_no_results'
                })
                return []

            # Format results
            formatted_results = []
            for row in result.data:
                formatted_results.append({
                    'page_id': row['id'],
                    'pdf_id': row['medical_record_id'],
                    'page_number': row['page_number'],
                    'content': row['content'],
                    'similarity': row['similarity']
                })

            total_duration = time.time() - start_time

            logger.info(f"PDF page semantic search completed", extra={
                'user_id': user_id,
                'pdf_id': pdf_id,
                'results_returned': len(formatted_results),
                'duration_seconds': total_duration,
                'db_duration_seconds': db_duration,
                'action': 'search_pdf_pages_complete'
            })

            return formatted_results

        except CircuitBreakerOpenException as e:
            duration = time.time() - start_time
            logger.warning(f"PDF search circuit breaker is open: {str(e)}", extra={
                'user_id': user_id,
                'pdf_id': pdf_id,
                'duration_seconds': duration,
                'action': 'search_pdf_pages_circuit_open'
            })
            return []
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"PDF page semantic search failed: {str(e)}", extra={
                'user_id': user_id,
                'pdf_id': pdf_id,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'search_pdf_pages_error'
            })
            return []

    def search_pdf_pages_by_text(
        self,
        pattern: str,
        user_id: str,
        supabase: SupabaseClient,
        pdf_id: Optional[str] = None,
        max_results: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Search PDF pages by text pattern (grep-style).

        Args:
            pattern: Text pattern to search for
            user_id: User ID to filter pages
            supabase: Supabase client for database operations
            pdf_id: Optional PDF ID to limit search to specific document
            max_results: Maximum number of results to return

        Returns:
            List of matching pages
        """
        start_time = time.time()

        logger.info(f"Starting PDF page text search for user {user_id}", extra={
            'user_id': user_id,
            'pdf_id': pdf_id,
            'pattern_length': len(pattern),
            'max_results': max_results,
            'action': 'search_pdf_pages_text_start'
        })

        try:
            # Call the RPC function for text search
            def search_query():
                return supabase.rpc('search_pdf_pages_by_text', {
                    'target_user_id': user_id,
                    'target_pdf_id': pdf_id,
                    'search_pattern': pattern,
                    'match_count': max_results
                }).execute()

            db_start = time.time()
            result = circuit_breaker.protect_query(search_query)
            db_duration = time.time() - db_start

            if not result.data:
                logger.info("No PDF pages found by text search", extra={
                    'user_id': user_id,
                    'pdf_id': pdf_id,
                    'db_duration_seconds': db_duration,
                    'action': 'search_pdf_pages_text_no_results'
                })
                return []

            # Format results
            formatted_results = []
            for row in result.data:
                formatted_results.append({
                    'page_id': row['id'],
                    'pdf_id': row['medical_record_id'],
                    'page_number': row['page_number'],
                    'content': row['content'],
                    'match_count': row['match_count']
                })

            total_duration = time.time() - start_time

            logger.info(f"PDF page text search completed", extra={
                'user_id': user_id,
                'pdf_id': pdf_id,
                'results_returned': len(formatted_results),
                'duration_seconds': total_duration,
                'db_duration_seconds': db_duration,
                'action': 'search_pdf_pages_text_complete'
            })

            return formatted_results

        except CircuitBreakerOpenException as e:
            duration = time.time() - start_time
            logger.warning(f"PDF text search circuit breaker is open: {str(e)}", extra={
                'user_id': user_id,
                'pdf_id': pdf_id,
                'duration_seconds': duration,
                'action': 'search_pdf_pages_text_circuit_open'
            })
            return []
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"PDF page text search failed: {str(e)}", extra={
                'user_id': user_id,
                'pdf_id': pdf_id,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'duration_seconds': duration,
                'action': 'search_pdf_pages_text_error'
            })
            return []


# Global instance for use across the application
semantic_search_service = SemanticSearchService()